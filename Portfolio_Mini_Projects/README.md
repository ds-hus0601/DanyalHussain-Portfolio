# Portfolio Mini-Projects

### Objective
Explore and test a range of data-science techniques through small, focused experiments covering anomaly detection, hyperparameter tuning, and regularisation.

---

### 🧮 Anomaly Detection Methods Comparison
Tested and compared unsupervised learning techniques including IQR, PCA, Isolation Forest, and One-Class SVM for identifying outliers in numeric datasets.

🔹 *Tech:* Python, Scikit-learn, NumPy, Matplotlib  
🔹 *Skills:* Unsupervised learning, model comparison, feature scaling

---

### ⚙️ Hyperparameter Tuning (Spambase Dataset)
Implemented grid search to optimise neural-network parameters such as learning rate, epochs, and batch size using the Spambase dataset.

🔹 *Tech:* Python, TensorFlow, Keras  
🔹 *Skills:* Model tuning, validation strategy, automation

---

### 🧠 Regularisation Experiments
Assessed dropout rates and L2 penalties to find the optimal balance between accuracy and generalisation in small-sample deep-learning models.

🔹 *Tech:* Python, TensorFlow, Keras  
🔹 *Skills:* Regularisation, model evaluation, overfitting prevention

---

### Key Learning
These experiments collectively strengthened understanding of model robustness, interpretability, and the trade-offs between complexity and performance.

