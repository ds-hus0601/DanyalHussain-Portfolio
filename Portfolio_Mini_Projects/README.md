# Portfolio Mini-Projects

### Objective
Explore and test a range of data-science techniques through small, focused experiments covering anomaly detection, hyperparameter tuning, and regularisation.

---

### ğŸ§® Anomaly Detection Methods Comparison
Tested and compared unsupervised learning techniques including IQR, PCA, Isolation Forest, and One-Class SVM for identifying outliers in numeric datasets.

ğŸ”¹ *Tech:* Python, Scikit-learn, NumPy, Matplotlib  
ğŸ”¹ *Skills:* Unsupervised learning, model comparison, feature scaling

---

### âš™ï¸ Hyperparameter Tuning (Spambase Dataset)
Implemented grid search to optimise neural-network parameters such as learning rate, epochs, and batch size using the Spambase dataset.

ğŸ”¹ *Tech:* Python, TensorFlow, Keras  
ğŸ”¹ *Skills:* Model tuning, validation strategy, automation

---

### ğŸ§  Regularisation Experiments
Assessed dropout rates and L2 penalties to find the optimal balance between accuracy and generalisation in small-sample deep-learning models.

ğŸ”¹ *Tech:* Python, TensorFlow, Keras  
ğŸ”¹ *Skills:* Regularisation, model evaluation, overfitting prevention

---

### Key Learning
These experiments collectively strengthened understanding of model robustness, interpretability, and the trade-offs between complexity and performance.

