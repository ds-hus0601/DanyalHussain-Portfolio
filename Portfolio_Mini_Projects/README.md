# 🧩 Portfolio Mini Projects

This collection highlights a series of focused, technical experiments completed as part of the **University of Cambridge Data Science & Machine Learning Career Accelerator (2025)** and extended personal explorations.  
Each mini-project demonstrates mastery of a specific data science concept — from model optimisation and clustering to neural network performance tuning and interpretability.

---

## 🌳 Decision Trees for Classification
Developed and evaluated Decision Tree and Random Forest models to classify tabular data, exploring interpretability and model generalisation.  
Visualised decision boundaries and analysed feature importance to understand key predictive variables.

🔹 *Tech:* Python, Scikit-learn, Matplotlib  
🔹 *Skills:* Supervised learning, feature importance, model evaluation

---

## 📈 Neural Network Regression
Built and tuned a feed-forward neural network for regression tasks, optimising learning rate and activation functions.  
Assessed performance using MAE and RMSE, and plotted loss curves to visualise convergence behaviour.

🔹 *Tech:* Python, TensorFlow, Scikit-learn  
🔹 *Skills:* Neural networks, regression analysis, model tuning

---

## ⚙️ Neural Network Optimisation & Regularisation
Investigated dropout layers, L2 regularisation, and optimiser choice (Adam vs RMSProp) to reduce overfitting in small datasets.  
Compared validation accuracy across tuning configurations and summarised convergence trends.

🔹 *Tech:* Python, TensorFlow, Keras  
🔹 *Skills:* Regularisation, hyperparameter tuning, model validation

---

## 👥 Customer Segmentation with Clustering *(Extended Concept)*
Expanded on clustering foundations by testing Recency–Frequency–Monetary (RFM) segmentation in small synthetic datasets.  
Compared K-Means, DBSCAN, and Hierarchical Clustering for different data distributions.

🔹 *Tech:* Python, Scikit-learn, Seaborn  
🔹 *Skills:* Clustering, unsupervised learning, data scaling

---

## 🧠 Key Learnings
- Applied both **supervised and unsupervised** machine learning methods for predictive and exploratory tasks.  
- Enhanced understanding of **model interpretability**, **hyperparameter optimisation**, and **regularisation techniques**.  
- Strengthened practical workflow in **Jupyter**, **Git**, and **Python-based data science pipelines**.

---

## 🛠️ Tools and Libraries
**Languages & Libraries:** Python (Pandas, NumPy, Scikit-learn, TensorFlow, Keras, Matplotlib, Seaborn)  
**Focus Areas:** Model Development, Regularisation, Clustering, Interpretability  
**Environment:** Jupyter, Colab, GitHub  

---

⭐ *These mini-projects represent the experimental foundation that underpins my larger applied work — each reinforcing technical depth, adaptability, and data storytelling.*
